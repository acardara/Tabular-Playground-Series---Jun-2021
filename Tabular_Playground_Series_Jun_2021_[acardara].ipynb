{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tabular Playground Series - Jun 2021 [acardara]",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderCardarasUCSC/Tabular-Playground-Series---Jun-2021/blob/main/Tabular_Playground_Series_Jun_2021_%5Bacardara%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti90w18y-uM7"
      },
      "source": [
        "### Introuction/Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f77-1WvV4cA8"
      },
      "source": [
        "Code entry for the **Tabular Playground Series - Jun 2021** kaggle competition.\n",
        "\n",
        "https://www.kaggle.com/c/tabular-playground-series-jun-2021/overview\n",
        "\n",
        "\n",
        "\n",
        "Inspiration for the code from the keras functional_api guide.\n",
        "\n",
        "https://keras.io/guides/functional_api/.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syOJbPyglvrw",
        "outputId": "c32e0091-3227-4615-9291-bbffefe21e70"
      },
      "source": [
        "# mount google drive to download dataset\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFk07fPWmL_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5d53b9-41c6-4164-9f6e-a9e35a868109"
      },
      "source": [
        "# create a folder to store dataset files\n",
        "!mkdir /content/dataset\n",
        "!mkdir /content/models\n",
        "\n",
        "# copy dataset from google drive\n",
        "!cp /content/gdrive/MyDrive/kaggle/train.csv /content/dataset\n",
        "!cp /content/gdrive/MyDrive/kaggle/test.csv /content/dataset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/dataset’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr8K3C4lTH_U"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def shuffle_data(data):\n",
        "  i = np.random.permutation(len(data))\n",
        "  new_data = data[i]\n",
        "  return new_data\n",
        "\n",
        "# def shuffle_data_xyz(x, y, z):\n",
        "#   i = np.random.permutation(len(x))\n",
        "#   new_x = x[i]\n",
        "#   new_y = y[i]\n",
        "#   new_z = z[i]\n",
        "#   return new_x, new_y, new_z\n",
        "\n",
        "def split_train_val(dataset, split=0.8, shuffle=True):\n",
        "  # shuffle rows in dataset\n",
        "  if shuffle:\n",
        "    dataset = shuffle_data(dataset)\n",
        "\n",
        "  train_set_length = int(len(dataset) * split)\n",
        "\n",
        "  # split dataset into real sets of \n",
        "  train_set = dataset[0:train_set_length]\n",
        "  val_set = dataset[train_set_length:]\n",
        "  return train_set, val_set\n",
        "\n",
        "def labels_to_int(labels):\n",
        "# applying to_categorical is currently causing an error, \n",
        "# TODO: implement it correctly\n",
        "  new_labels = []\n",
        "  for label in labels:\n",
        "    # we want the 6th character of each class label string ie 'Class_7' should \n",
        "    # convert to '7'\n",
        "\n",
        "    # to_categorical expects values to start from 0, dataset is in range [1,9]\n",
        "    # we must subtract 1 from class labels for training to get the range [0,8]\n",
        "    new_labels.append(int(label[-1])-1)\n",
        "  new_labels = np.asarray(new_labels)\n",
        "  # return to_categorical(new_labels, NUMBER_OF_CLASSES)\n",
        "  return new_labels\n",
        "\n",
        "def split_data(dataset, is_test=False):\n",
        "  if not is_test:\n",
        "    id = dataset[:,0]\n",
        "    features = dataset[:,1:-1]\n",
        "    label = dataset[:,-1]\n",
        "    label = labels_to_int(label)\n",
        "  else:\n",
        "    id = dataset[:,0]\n",
        "    features = dataset[:,1:]\n",
        "    label = None\n",
        "  return id, features, label"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZymkdKknKX0",
        "outputId": "230b62ac-0a67-4428-9e2e-c8d4c17066ad"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_dataset_train = pd.read_csv(\"/content/dataset/train.csv\", header=0)\n",
        "np_dataset_train = raw_dataset_train.to_numpy()\n",
        "train, val = split_train_val(np_dataset_train)\n",
        "\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "\n",
        "# dataset_train = raw_dataset.to_numpy()[0:140_000]\n",
        "# dataset_validation = raw_dataset.to_numpy()[140_000:]\n",
        "\n",
        "# print(dataset_train.shape)\n",
        "# print(dataset_validation.shape)\n",
        "\n",
        "raw_testset = pd.read_csv(\"/content/dataset/test.csv\", header=0)\n",
        "np_testset = raw_testset.to_numpy()\n",
        "test, _ = split_train_val(np_testset, split=1, shuffle=False)\n",
        "print(test.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 77)\n",
            "(40000, 77)\n",
            "(100000, 76)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch-L8LPG-1O1"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVXp8SKcojCu"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "NUMBER_OF_CLASSES = 9\n",
        "SUMMARIZE_AFTER = 1\n",
        "\n",
        "def generate_training_samples(features, labels, n_samples):\n",
        "  rows = np.random.permutation(features.shape[0])[0:n_samples]\n",
        "\n",
        "  x = features[rows].astype(\"float32\")\n",
        "  y = labels[rows].astype(\"float32\")\n",
        "\n",
        "  return x, y\n",
        "\n",
        "# print accuracy of holdout dataset\n",
        "def summarize_performance(features, labels, model, epoch):\n",
        "  train_x, train_y = generate_training_samples(features, labels, features.shape[0])\n",
        "  _loss, _accuracy = model.evaluate(train_x, train_y)\n",
        "  return _loss\n",
        "\n",
        "def train_model(dataset_train, dataset_validation, model, n_epochs, batch_size, save_dir=\"/content/models/\"):\n",
        "  train_ids, train_features, train_labels = split_data(dataset_train)\n",
        "  val_ids, val_features, val_labels = split_data(dataset_validation)\n",
        "\n",
        "  iterations_per_epoch = dataset_train.shape[0]\n",
        "  batches_per_epoch = iterations_per_epoch//batch_size\n",
        "  for epoch in range(n_epochs):\n",
        "    temp_train_loss = []\n",
        "\n",
        "    for batch in range(batches_per_epoch):\n",
        "        train_x, train_y = generate_training_samples(train_features, train_labels, batch_size)\n",
        "        _loss, _accuracy = model.train_on_batch(train_x, train_y)\n",
        "        temp_train_loss.append(_loss)\n",
        "\n",
        "        if batch % 200 == 0:\n",
        "          print(\">%d %d/%d, %.3f, %.3f\"%(epoch, batch, batches_per_epoch, _loss, _accuracy))\n",
        "\n",
        "    # print metrics every epoch\n",
        "    if (epoch + 1) % SUMMARIZE_AFTER == 0:\n",
        "      train_loss.append(sum(temp_train_loss)/len(temp_train_loss))\n",
        "      val_loss = summarize_performance(val_features, val_labels, model, epoch)\n",
        "      validation_loss.append(val_loss)\n",
        "      checkpoint_name = save_dir+str(epoch).zfill(4)+\".h5\"\n",
        "      model.save(checkpoint_name)\n",
        "      model_checkpoints.append(checkpoint_name)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLjWd7qO_A5G"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeWWVGTB_AaO"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def define_baseline_model():\n",
        "  input_layer = Input(shape=(75,), name=\"First_Layer\")\n",
        "\n",
        "  output_layer = Dense(128, activation=\"relu\")(input_layer)\n",
        "  output_layer = Dropout(0.4)(output_layer)\n",
        "  \n",
        "  output_layer = Dense(64, activation=\"relu\")(output_layer)\n",
        "  output_layer = Dense(NUMBER_OF_CLASSES, activation=\"softmax\")(output_layer)\n",
        "  \n",
        "  model = Model(inputs=input_layer, outputs=output_layer, name=\"Simple_Classification_Model\")\n",
        "\n",
        "  loss = SparseCategoricalCrossentropy()\n",
        "  opt = Adam(learning_rate=0.0005, beta_1=0.8)\n",
        "  model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfoehBkU_FaJ"
      },
      "source": [
        "### Train Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oPG2bg_Dw4Qw",
        "outputId": "36b1244f-7717-4570-ec2f-326b0d55a1ef"
      },
      "source": [
        "train_loss, validation_loss, model_checkpoints = [], [], []\n",
        "\n",
        "n_epochs = 50\n",
        "batch_size = 100\n",
        "\n",
        "model = define_baseline_model()\n",
        "\n",
        "model.summary()\n",
        "train_model(train, val, model, n_epochs, batch_size)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Simple_Classification_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "First_Layer (InputLayer)     [(None, 75)]              0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 128)               9728      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 9)                 585       \n",
            "=================================================================\n",
            "Total params: 18,569\n",
            "Trainable params: 18,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            ">0 0/1600, 5.497, 0.160\n",
            ">0 200/1600, 2.269, 0.200\n",
            ">0 400/1600, 2.110, 0.270\n",
            ">0 600/1600, 2.125, 0.240\n",
            ">0 800/1600, 1.927, 0.320\n",
            ">0 1000/1600, 1.978, 0.340\n",
            ">0 1200/1600, 1.821, 0.270\n",
            ">0 1400/1600, 1.979, 0.340\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8555 - accuracy: 0.3185\n",
            ">1 0/1600, 1.855, 0.319\n",
            ">1 200/1600, 1.872, 0.270\n",
            ">1 400/1600, 1.727, 0.370\n",
            ">1 600/1600, 1.936, 0.260\n",
            ">1 800/1600, 1.859, 0.340\n",
            ">1 1000/1600, 1.790, 0.360\n",
            ">1 1200/1600, 1.867, 0.300\n",
            ">1 1400/1600, 1.808, 0.320\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8072 - accuracy: 0.3427\n",
            ">2 0/1600, 1.807, 0.343\n",
            ">2 200/1600, 1.875, 0.330\n",
            ">2 400/1600, 1.860, 0.390\n",
            ">2 600/1600, 1.761, 0.320\n",
            ">2 800/1600, 1.766, 0.360\n",
            ">2 1000/1600, 1.870, 0.310\n",
            ">2 1200/1600, 1.754, 0.390\n",
            ">2 1400/1600, 1.813, 0.270\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7900 - accuracy: 0.3469\n",
            ">3 0/1600, 1.790, 0.347\n",
            ">3 200/1600, 1.981, 0.270\n",
            ">3 400/1600, 1.738, 0.320\n",
            ">3 600/1600, 1.871, 0.240\n",
            ">3 800/1600, 1.747, 0.340\n",
            ">3 1000/1600, 1.858, 0.320\n",
            ">3 1200/1600, 1.761, 0.420\n",
            ">3 1400/1600, 1.741, 0.400\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7812 - accuracy: 0.3498\n",
            ">4 0/1600, 1.781, 0.350\n",
            ">4 200/1600, 1.784, 0.330\n",
            ">4 400/1600, 1.829, 0.280\n",
            ">4 600/1600, 1.764, 0.400\n",
            ">4 800/1600, 1.804, 0.370\n",
            ">4 1000/1600, 1.819, 0.270\n",
            ">4 1200/1600, 1.710, 0.380\n",
            ">4 1400/1600, 1.831, 0.360\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7756 - accuracy: 0.3524\n",
            ">5 0/1600, 1.775, 0.352\n",
            ">5 200/1600, 1.695, 0.380\n",
            ">5 400/1600, 1.864, 0.340\n",
            ">5 600/1600, 1.866, 0.310\n",
            ">5 800/1600, 1.819, 0.330\n",
            ">5 1000/1600, 1.810, 0.340\n",
            ">5 1200/1600, 1.801, 0.300\n",
            ">5 1400/1600, 1.926, 0.300\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7716 - accuracy: 0.3550\n",
            ">6 0/1600, 1.771, 0.355\n",
            ">6 200/1600, 1.867, 0.310\n",
            ">6 400/1600, 1.676, 0.390\n",
            ">6 600/1600, 1.638, 0.390\n",
            ">6 800/1600, 1.623, 0.430\n",
            ">6 1000/1600, 1.768, 0.360\n",
            ">6 1200/1600, 1.670, 0.340\n",
            ">6 1400/1600, 1.719, 0.410\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7715 - accuracy: 0.3541\n",
            ">7 0/1600, 1.772, 0.354\n",
            ">7 200/1600, 1.697, 0.370\n",
            ">7 400/1600, 1.882, 0.340\n",
            ">7 600/1600, 1.832, 0.300\n",
            ">7 800/1600, 1.831, 0.370\n",
            ">7 1000/1600, 1.670, 0.390\n",
            ">7 1200/1600, 1.831, 0.330\n",
            ">7 1400/1600, 1.651, 0.410\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7683 - accuracy: 0.3535\n",
            ">8 0/1600, 1.768, 0.354\n",
            ">8 200/1600, 1.704, 0.370\n",
            ">8 400/1600, 1.748, 0.400\n",
            ">8 600/1600, 1.767, 0.400\n",
            ">8 800/1600, 1.717, 0.380\n",
            ">8 1000/1600, 1.823, 0.290\n",
            ">8 1200/1600, 1.780, 0.400\n",
            ">8 1400/1600, 1.805, 0.350\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7680 - accuracy: 0.3534\n",
            ">9 0/1600, 1.768, 0.353\n",
            ">9 200/1600, 1.586, 0.450\n",
            ">9 400/1600, 1.599, 0.400\n",
            ">9 600/1600, 1.865, 0.280\n",
            ">9 800/1600, 1.745, 0.410\n",
            ">9 1000/1600, 1.806, 0.370\n",
            ">9 1200/1600, 1.816, 0.350\n",
            ">9 1400/1600, 1.756, 0.400\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7677 - accuracy: 0.3554\n",
            ">10 0/1600, 1.768, 0.356\n",
            ">10 200/1600, 1.851, 0.330\n",
            ">10 400/1600, 1.803, 0.310\n",
            ">10 600/1600, 1.750, 0.310\n",
            ">10 800/1600, 1.677, 0.360\n",
            ">10 1000/1600, 1.672, 0.410\n",
            ">10 1200/1600, 1.665, 0.410\n",
            ">10 1400/1600, 1.835, 0.370\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7662 - accuracy: 0.3559\n",
            ">11 0/1600, 1.766, 0.356\n",
            ">11 200/1600, 1.864, 0.290\n",
            ">11 400/1600, 1.784, 0.330\n",
            ">11 600/1600, 1.911, 0.300\n",
            ">11 800/1600, 1.627, 0.420\n",
            ">11 1000/1600, 1.825, 0.340\n",
            ">11 1200/1600, 1.852, 0.320\n",
            ">11 1400/1600, 1.818, 0.320\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7654 - accuracy: 0.3568\n",
            ">12 0/1600, 1.765, 0.357\n",
            ">12 200/1600, 1.734, 0.370\n",
            ">12 400/1600, 1.802, 0.420\n",
            ">12 600/1600, 1.666, 0.350\n",
            ">12 800/1600, 1.805, 0.320\n",
            ">12 1000/1600, 1.633, 0.430\n",
            ">12 1200/1600, 1.693, 0.360\n",
            ">12 1400/1600, 1.746, 0.350\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7656 - accuracy: 0.3554\n",
            ">13 0/1600, 1.766, 0.355\n",
            ">13 200/1600, 1.835, 0.290\n",
            ">13 400/1600, 1.673, 0.450\n",
            ">13 600/1600, 1.835, 0.290\n",
            ">13 800/1600, 1.656, 0.400\n",
            ">13 1000/1600, 1.841, 0.300\n",
            ">13 1200/1600, 1.921, 0.320\n",
            ">13 1400/1600, 1.650, 0.400\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7661 - accuracy: 0.3547\n",
            ">14 0/1600, 1.766, 0.355\n",
            ">14 200/1600, 1.712, 0.380\n",
            ">14 400/1600, 1.700, 0.360\n",
            ">14 600/1600, 1.882, 0.310\n",
            ">14 800/1600, 1.829, 0.320\n",
            ">14 1000/1600, 1.923, 0.260\n",
            ">14 1200/1600, 1.768, 0.350\n",
            ">14 1400/1600, 1.787, 0.390\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7656 - accuracy: 0.3562\n",
            ">15 0/1600, 1.766, 0.356\n",
            ">15 200/1600, 1.568, 0.470\n",
            ">15 400/1600, 1.959, 0.260\n",
            ">15 600/1600, 1.667, 0.340\n",
            ">15 800/1600, 1.705, 0.360\n",
            ">15 1000/1600, 1.761, 0.390\n",
            ">15 1200/1600, 1.736, 0.340\n",
            ">15 1400/1600, 1.779, 0.340\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7640 - accuracy: 0.3565\n",
            ">16 0/1600, 1.764, 0.356\n",
            ">16 200/1600, 1.708, 0.380\n",
            ">16 400/1600, 1.875, 0.240\n",
            ">16 600/1600, 1.782, 0.310\n",
            ">16 800/1600, 1.732, 0.390\n",
            ">16 1000/1600, 1.672, 0.350\n",
            ">16 1200/1600, 1.717, 0.340\n",
            ">16 1400/1600, 1.773, 0.330\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7634 - accuracy: 0.3566\n",
            ">17 0/1600, 1.763, 0.357\n",
            ">17 200/1600, 1.697, 0.360\n",
            ">17 400/1600, 1.783, 0.300\n",
            ">17 600/1600, 1.763, 0.300\n",
            ">17 800/1600, 1.712, 0.380\n",
            ">17 1000/1600, 1.748, 0.360\n",
            ">17 1200/1600, 1.734, 0.340\n",
            ">17 1400/1600, 1.910, 0.300\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7635 - accuracy: 0.3560\n",
            ">18 0/1600, 1.763, 0.356\n",
            ">18 200/1600, 1.593, 0.420\n",
            ">18 400/1600, 1.651, 0.370\n",
            ">18 600/1600, 1.872, 0.290\n",
            ">18 800/1600, 1.677, 0.430\n",
            ">18 1000/1600, 1.746, 0.350\n",
            ">18 1200/1600, 1.727, 0.340\n",
            ">18 1400/1600, 1.750, 0.400\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7637 - accuracy: 0.3567\n",
            ">19 0/1600, 1.764, 0.357\n",
            ">19 200/1600, 1.857, 0.370\n",
            ">19 400/1600, 1.665, 0.430\n",
            ">19 600/1600, 1.822, 0.270\n",
            ">19 800/1600, 1.651, 0.420\n",
            ">19 1000/1600, 1.562, 0.410\n",
            ">19 1200/1600, 1.893, 0.310\n",
            ">19 1400/1600, 1.822, 0.290\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7637 - accuracy: 0.3550\n",
            ">20 0/1600, 1.764, 0.355\n",
            ">20 200/1600, 1.951, 0.320\n",
            ">20 400/1600, 1.880, 0.260\n",
            ">20 600/1600, 1.739, 0.400\n",
            ">20 800/1600, 1.730, 0.410\n",
            ">20 1000/1600, 1.850, 0.310\n",
            ">20 1200/1600, 1.797, 0.330\n",
            ">20 1400/1600, 1.757, 0.310\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7633 - accuracy: 0.3560\n",
            ">21 0/1600, 1.763, 0.356\n",
            ">21 200/1600, 1.746, 0.370\n",
            ">21 400/1600, 1.758, 0.340\n",
            ">21 600/1600, 1.608, 0.430\n",
            ">21 800/1600, 1.816, 0.380\n",
            ">21 1000/1600, 1.625, 0.380\n",
            ">21 1200/1600, 1.764, 0.310\n",
            ">21 1400/1600, 1.767, 0.390\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7641 - accuracy: 0.3564\n",
            ">22 0/1600, 1.764, 0.357\n",
            ">22 200/1600, 1.604, 0.440\n",
            ">22 400/1600, 1.734, 0.340\n",
            ">22 600/1600, 1.765, 0.330\n",
            ">22 800/1600, 1.714, 0.420\n",
            ">22 1000/1600, 1.757, 0.330\n",
            ">22 1200/1600, 1.788, 0.350\n",
            ">22 1400/1600, 1.650, 0.440\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7646 - accuracy: 0.3550\n",
            ">23 0/1600, 1.764, 0.355\n",
            ">23 200/1600, 1.869, 0.350\n",
            ">23 400/1600, 1.743, 0.370\n",
            ">23 600/1600, 1.807, 0.320\n",
            ">23 800/1600, 1.707, 0.350\n",
            ">23 1000/1600, 1.708, 0.380\n",
            ">23 1200/1600, 1.703, 0.390\n",
            ">23 1400/1600, 1.646, 0.420\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7642 - accuracy: 0.3553\n",
            ">24 0/1600, 1.765, 0.355\n",
            ">24 200/1600, 1.700, 0.390\n",
            ">24 400/1600, 1.805, 0.370\n",
            ">24 600/1600, 1.736, 0.410\n",
            ">24 800/1600, 1.625, 0.370\n",
            ">24 1000/1600, 1.871, 0.310\n",
            ">24 1200/1600, 1.797, 0.310\n",
            ">24 1400/1600, 1.787, 0.370\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7639 - accuracy: 0.3568\n",
            ">25 0/1600, 1.764, 0.357\n",
            ">25 200/1600, 1.764, 0.380\n",
            ">25 400/1600, 1.842, 0.320\n",
            ">25 600/1600, 1.798, 0.320\n",
            ">25 800/1600, 1.662, 0.420\n",
            ">25 1000/1600, 1.667, 0.390\n",
            ">25 1200/1600, 1.636, 0.350\n",
            ">25 1400/1600, 1.708, 0.320\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7640 - accuracy: 0.3561\n",
            ">26 0/1600, 1.764, 0.356\n",
            ">26 200/1600, 1.842, 0.340\n",
            ">26 400/1600, 1.731, 0.390\n",
            ">26 600/1600, 1.872, 0.390\n",
            ">26 800/1600, 1.874, 0.340\n",
            ">26 1000/1600, 1.648, 0.390\n",
            ">26 1200/1600, 1.913, 0.280\n",
            ">26 1400/1600, 1.668, 0.370\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7643 - accuracy: 0.3558\n",
            ">27 0/1600, 1.764, 0.356\n",
            ">27 200/1600, 1.804, 0.370\n",
            ">27 400/1600, 1.731, 0.350\n",
            ">27 600/1600, 1.643, 0.420\n",
            ">27 800/1600, 1.737, 0.380\n",
            ">27 1000/1600, 1.728, 0.320\n",
            ">27 1200/1600, 1.709, 0.380\n",
            ">27 1400/1600, 1.751, 0.390\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7644 - accuracy: 0.3551\n",
            ">28 0/1600, 1.764, 0.355\n",
            ">28 200/1600, 1.810, 0.340\n",
            ">28 400/1600, 1.827, 0.340\n",
            ">28 600/1600, 1.624, 0.380\n",
            ">28 800/1600, 1.785, 0.400\n",
            ">28 1000/1600, 1.636, 0.380\n",
            ">28 1200/1600, 1.643, 0.370\n",
            ">28 1400/1600, 1.781, 0.370\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7644 - accuracy: 0.3552\n",
            ">29 0/1600, 1.764, 0.355\n",
            ">29 200/1600, 1.637, 0.440\n",
            ">29 400/1600, 1.632, 0.440\n",
            ">29 600/1600, 1.826, 0.330\n",
            ">29 800/1600, 1.697, 0.380\n",
            ">29 1000/1600, 1.823, 0.300\n",
            ">29 1200/1600, 1.683, 0.380\n",
            ">29 1400/1600, 1.836, 0.310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-f64bcea3f824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-91dd07937a03>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataset_train, dataset_validation, model, n_epochs, batch_size, save_dir)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtemp_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-91dd07937a03>\u001b[0m in \u001b[0;36mgenerate_training_samples\u001b[0;34m(features, labels, n_samples)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEE5sIbvpdPG"
      },
      "source": [
        "### Visualize losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jRnMb_tBMde0",
        "outputId": "8ccf63a5-3127-447f-8eb0-9691f25cf098"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "x = [SUMMARIZE_AFTER*i for i in range(len(train_loss))]\n",
        "plt.plot(x, train_loss)\n",
        "plt.plot(x, validation_loss)\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYmfiUZJ2opX",
        "outputId": "2fe51bb6-ff2a-4eef-d784-6111cfdcb9ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "val_ids, val_features, val_labels = split_data(val)\n",
        "\n",
        "for epoch, model_name in enumerate(model_checkpoints):\n",
        "  temp_model = load_model(model_name)\n",
        "  summarize_performance(val_features, val_labels, temp_model, epoch)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8572 - accuracy: 0.3277\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.8032 - accuracy: 0.3452\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7885 - accuracy: 0.3477\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7794 - accuracy: 0.3510\n",
            "1250/1250 [==============================] - 2s 2ms/step - loss: 1.7742 - accuracy: 0.3517\n",
            " 543/1250 [============>.................] - ETA: 1s - loss: 1.7815 - accuracy: 0.3530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-9d7f22a7b885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-91dd07937a03>\u001b[0m in \u001b[0;36msummarize_performance\u001b[0;34m(features, labels, model, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERPHrQmFnrdj"
      },
      "source": [
        "### Run Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ls4OhQnyYO"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def predict_class(model, features):\n",
        "  features = np.expand_dims(features, axis=0)\n",
        "  return model.predict(features)\n",
        "\n",
        "def predict_testset(model, test_ids, test_features):\n",
        "  labels = [\"id\",\"Class_1\",\"Class_2\",\"Class_3\",\"Class_4\",\"Class_5\",\"Class_6\",\"Class_7\",\"Class_8\",\"Class_9\"]\n",
        "  \n",
        "  results = []\n",
        "  # ids = testset[:,0]\n",
        "  ids = test_ids.reshape((test_ids.shape[0]), 1)\n",
        "  ids = pd.DataFrame(data=ids, columns=[labels[0]])\n",
        "\n",
        "  # data = testset[:,1:]\n",
        "  results = model.predict(test_features)\n",
        "  results = pd.DataFrame(data=results, columns=labels[1:])\n",
        "\n",
        "  final = pd.concat([ids, results], axis=1)\n",
        "  # final = np.hstack((ids,results))\n",
        "\n",
        "  # return pd.DataFrame(data=final, columns=labels)\n",
        "  return final\n",
        "\n",
        "\n",
        "test_model = load_model(model_checkpoints[20])\n",
        "test_ids, test_features, _ = split_data(test, is_test=True)\n",
        "results = predict_testset(model, test_ids, test_features)\n",
        "results.to_csv(\"submission.csv\", index=False)\n",
        "# print(results)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZfu_PgDMrBW"
      },
      "source": [
        "### UMAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ct7HXMTMLxJ"
      },
      "source": [
        "!pip install umap-learn\n",
        "!pip install babyplots\n",
        "!pip install hdbscan "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG7FnLQB6WXZ"
      },
      "source": [
        "import umap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from babyplots import Babyplot\n",
        "import hdbscan\n",
        "\n",
        "\n",
        "\n",
        "dataset = raw_dataset.to_numpy()[:,1:-1]\n",
        "labels = raw_dataset.to_numpy()[:,-1]\n",
        "\n",
        "dataset = StandardScaler().fit_transform(dataset)\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "class_names = [\"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\", \"Class_5\", \"Class_6\", \"Class_7\", \"Class_8\", \"Class_9\"]\n",
        "le.fit(class_names)\n",
        "labels = le.transform(labels)\n",
        "\n",
        "print(labels)\n",
        "print(dataset)\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.30)\n",
        "reducer2d = umap.UMAP(n_neighbors=20,\n",
        "                        min_dist=0.0,\n",
        "                        n_components=2,\n",
        "                        random_state=42, metric='euclidean', target_weight=0)\n",
        "\n",
        "reducer3d = umap.UMAP(n_neighbors=20,\n",
        "                      min_dist=0.0,\n",
        "                      n_components=3,\n",
        "                      random_state=42, metric='euclidean', target_weight=0)\n",
        "\n",
        "# mapper2d = reducer2d.fit(X_train, y_train)\n",
        "mapper3d = reducer3d.fit(X_train, y_train)\n",
        "\n",
        "# embedding2d_train = mapper2d.transform(X_train)\n",
        "embedding3d_train = mapper3d.transform(X_train)\n",
        "\n",
        "\n",
        "\n",
        "# embedding2d_test = mapper2d.transform(X_test)\n",
        "embedding3d_test = mapper3d.transform(X_test)\n",
        "\n",
        "# embedding2d = embedding2d_train.tolist() + embedding2d_test.tolist()\n",
        "embedding3d = embedding3d_train.tolist() + embedding3d_test.tolist()\n",
        "# y_test \n",
        "print(y_test.shape)\n",
        "# y_test = np.where(y_test >= 1, 'RI', 'DE')\n",
        "y_plot = y_train.tolist() + y_test.tolist()\n",
        "bp = Babyplot(background_color=\"#ffffddff\", )\n",
        "bp.add_plot(embedding3d, 'pointCloud', 'categories', y_plot, {\n",
        "    'colorScale': 'Viridis',\n",
        "    'showLegend': True,\n",
        "    'folded': True,\n",
        "    'size': 5,\n",
        "    'showAxes': [True, True, True],\n",
        "    'axisLabels': ['X', 'Y', 'Z'],\n",
        "    'showTickLines': [[True, True], [True, True], [True, True]]\n",
        "})\n",
        "bp.save_as_html(r'/content/test3.html')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU9_sM1Amhg3"
      },
      "source": [
        "import hdbscan\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dataset = raw_dataset.to_numpy()[:,1:-1]\n",
        "labels = raw_dataset.to_numpy()[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tFXKnlQmicB"
      },
      "source": [
        "hdbscan_labels = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=500).fit_predict(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}